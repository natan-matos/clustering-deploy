{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69667/2663535302.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/home/natan/.pyenv/versions/3.11-dev/envs/envcluster/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inflection\n",
    "import umap as umap\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition as dd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_s3 = 's3://insiders-dataset-nm'\n",
    "data = pd.read_excel( path_s3 + '/Online Retail.xlsx/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
    "       'UnitPrice', 'CustomerID', 'Country']\n",
    "\n",
    "snakecase = lambda x: inflection.underscore( x ) # change to snakecase\n",
    "cols_new = list( map( snakecase, cols_old ))\n",
    "\n",
    "data.columns = cols_new # define the new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Check and fillout Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NA\n",
    "df_missing = data[data['customer_id'].isna()]\n",
    "df_not_missing = data[~data['customer_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reference\n",
    "backup = pd.DataFrame(df_missing['invoice_no'].drop_duplicates())\n",
    "backup['customer_id'] = np.arange(19000, 19000+len(backup), 1)\n",
    "\n",
    "# merge original data frame\n",
    "df1 = pd.merge(data, backup, on='invoice_no', how='left')\n",
    "\n",
    "#coalesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first(df1['customer_id_y'])\n",
    "\n",
    "# drop columns\n",
    "df1 = df1.drop(columns=['customer_id_x', 'customer_id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Change dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice data to datetime\n",
    "df1['invoice_date'] = pd.to_datetime(df1['invoice_date'], format='%d-%b-%y')\n",
    "#df1['invoice_date'] = df1['invoice_date'].dt.date\n",
    "\n",
    "# customer id\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Filtragem de variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit price > 0.04\n",
    "df2 = df2.loc[df2['unit_price'] >= 0.04, :]\n",
    "\n",
    "# stock code \n",
    "df2 = df2[~df2['stock_code'].isin(['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY', 'DCGSSGIRL','PADS', 'B', 'CRUK'])]\n",
    "\n",
    "# description\n",
    "df2 = df2.drop(columns='description', axis=1)\n",
    "\n",
    "#map\n",
    "df2 = df2[~df2['country'].isin(['European Community', 'Unspecified'])]\n",
    "\n",
    "# bad users\n",
    "df2 = df2[~df2['customer_id'].isin([16446])]\n",
    "\n",
    "# quantity - negative numbers means product returns\n",
    "df2_returns = df2.loc[df2['quantity'] < 0, :]\n",
    "df2_purchases = df2.loc[df2['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date reference \n",
    "df_ref = df2_purchases.drop(['invoice_no', 'stock_code',\n",
    "                   'quantity', 'invoice_date', 'unit_price', \n",
    "                   'country'], axis=1).drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ref.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69667/206990356.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2_purchases.loc[:, 'gross_revenue'] = df2_purchases.loc[:, 'quantity'] * df2_purchases.loc[:, 'unit_price']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gross Revenue ( Faturamento ) quantity * price\n",
    "df2_purchases.loc[:, 'gross_revenue'] = df2_purchases.loc[:, 'quantity'] * df2_purchases.loc[:, 'unit_price']\n",
    "\n",
    "# Monetary\n",
    "df_monetary = df2_purchases.loc[:, ['customer_id', 'gross_revenue']].groupby( 'customer_id' ).sum().reset_index()\n",
    "df_ref = pd.merge( df_ref, df_monetary, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recency - Last day purchase\n",
    "df_recency = df2_purchases.loc[:, ['customer_id', 'invoice_date']].groupby( 'customer_id' ).max().reset_index()\n",
    "df_recency['recency_days'] = ( df2['invoice_date'].max() - df_recency['invoice_date'] ).dt.days\n",
    "df_recency['recency_days'] = df_recency['recency_days'].apply( lambda x: 1/x if x !=0 else 1)\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge( df_ref, df_recency, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qtde_invoices\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'invoice_no']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id' )\n",
    "                                                             .count()\n",
    "                                                             .reset_index()\n",
    "                                                             .rename( columns={'invoice_no': 'qtde_invoices'}) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qtde_items\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'quantity']].groupby( 'customer_id' ).sum()\n",
    "                                                           .reset_index()\n",
    "                                                           .rename( columns={'quantity': 'qtde_items'} ) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "qtde_products    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de produtos\n",
    "df_freq = (df2_purchases.loc[:, ['customer_id', 'stock_code']].groupby( 'customer_id' ).count()\n",
    "                                                           .reset_index()\n",
    "                                                           .rename( columns={'stock_code': 'qtde_products'} ) )\n",
    "df_ref = pd.merge( df_ref, df_freq, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id      0\n",
       "gross_revenue    0\n",
       "recency_days     0\n",
       "qtde_invoices    0\n",
       "qtde_items       0\n",
       "qtde_products    0\n",
       "avg_ticket       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avg Ticket\n",
    "df_avg_ticket = df2_purchases.loc[:, ['customer_id', 'gross_revenue']].groupby( 'customer_id' ).mean().reset_index().rename( columns={'gross_revenue':'avg_ticket'} )\n",
    "df_ref = pd.merge( df_ref, df_avg_ticket, on='customer_id', how='left')\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average recency days\n",
    "df_aux = df2[['customer_id', 'invoice_date']].drop_duplicates().sort_values( ['customer_id', 'invoice_date'], ascending= False )\n",
    "df_aux['next_customer_id'] = df_aux['customer_id'].shift() # next customer\n",
    "df_aux['previous_date'] = df_aux['invoice_date'].shift() # next invoince date\n",
    "\n",
    "df_aux['avg_recency_days'] = df_aux.apply( lambda x: ( x['previous_date'] - x['invoice_date'] ).days if x['customer_id'] == x['next_customer_id'] else 0, axis=1 )\n",
    "df_aux['avg_recency_days'] = -1* df_aux['avg_recency_days'].apply( lambda x: 1/x if x!=0 else 1)\n",
    "\n",
    "df_aux = df_aux.drop( ['invoice_date', 'next_customer_id', 'previous_date'], axis=1 ).dropna()\n",
    "\n",
    "# average recency \n",
    "df_avg_recency_days = df_aux.groupby( 'customer_id' ).mean().reset_index()\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_avg_recency_days, on='customer_id', how='left' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frquency\n",
    "df_aux = ( df2_purchases[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                             .groupby( 'customer_id')\n",
    "                                                             .agg( max_ = ( 'invoice_date', 'max' ), \n",
    "                                                                   min_ = ( 'invoice_date', 'min' ),\n",
    "                                                                   days_= ( 'invoice_date', lambda x: ( ( x.max() - x.min() ).days ) + 1 ),\n",
    "                                                                   buy_ = ( 'invoice_no', 'count' ) ) ).reset_index()\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[['buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if  x['days_'] != 0 else 0, axis=1 )\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left' )\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "qtde_returns        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Returns\n",
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby( 'customer_id' ).sum().reset_index().rename( columns={'quantity':'qtde_returns'} )\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns'] * -1\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns'].apply( lambda x: 1/x if x!= 0 else 0)\n",
    "\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, how='left', on='customer_id' )\n",
    "df_ref.loc[df_ref['qtde_returns'].isna(), 'qtde_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id         0\n",
       "gross_revenue       0\n",
       "recency_days        0\n",
       "qtde_invoices       0\n",
       "qtde_items          0\n",
       "qtde_products       0\n",
       "avg_ticket          0\n",
       "avg_recency_days    0\n",
       "frequency           0\n",
       "qtde_returns        0\n",
       "avg_basket_size     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg_basket_size\n",
    "df_aux = ( df2_purchases.loc[:, ['customer_id', 'invoice_no', 'quantity']].groupby( 'customer_id' )\n",
    "                                                                            .agg( n_purchase=( 'invoice_no', 'nunique'),\n",
    "                                                                                  n_products=( 'quantity', 'sum' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'avg_basket_size']], how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id               0\n",
       "gross_revenue             0\n",
       "recency_days              0\n",
       "qtde_invoices             0\n",
       "qtde_items                0\n",
       "qtde_products             0\n",
       "avg_ticket                0\n",
       "avg_recency_days          0\n",
       "frequency                 0\n",
       "qtde_returns              0\n",
       "avg_basket_size           0\n",
       "avg_unique_basket_size    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avg_unique_basket_size\n",
    "df_aux = ( df2_purchases.loc[:, ['customer_id', 'invoice_no', 'stock_code']].groupby( 'customer_id' )\n",
    "                                                                            .agg( n_purchase=( 'invoice_no', 'nunique'),\n",
    "                                                                                   n_products=( 'stock_code', 'nunique' ) )\n",
    "                                                                            .reset_index() )\n",
    "\n",
    "# calculation\n",
    "df_aux['avg_unique_basket_size'] = df_aux['n_products'] / df_aux['n_purchase']\n",
    "\n",
    "# merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'avg_unique_basket_size']], how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69667/428756391.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customers_return.loc[:, 'revenue_returned'] = customers_return.loc[:, 'quantity'] * customers_return.loc[:, 'unit_price']\n"
     ]
    }
   ],
   "source": [
    "# money returned\n",
    "customers_return = df2[df2['quantity']< 0]\n",
    "customers_return.loc[:, 'revenue_returned'] = customers_return.loc[:, 'quantity'] * customers_return.loc[:, 'unit_price']\n",
    "revenue_returned = customers_return.groupby('customer_id')['revenue_returned'].sum().reset_index()\n",
    "revenue_returned['revenue_returned'] = revenue_returned['revenue_returned']\n",
    "\n",
    "df_ref = pd.merge(df_ref, revenue_returned, on='customer_id', how='left')\n",
    "df_ref = df_ref.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = df_ref.dropna()\n",
    "df4 = df_ref.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Estudo de Espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_no_scale = df4.drop( columns=['customer_id'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.4 Tree-Based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df4_no_scale.drop( columns=['gross_revenue'], axis=1 )\n",
    "y = df4_no_scale['gross_revenue']\n",
    "\n",
    "# model definition\n",
    "rf = RandomForestRegressor( n_estimators=100,\n",
    "                           criterion='friedman_mse',\n",
    "                           random_state=42)\n",
    "# model training\n",
    "rf.fit(X, y)\n",
    "\n",
    "# dataframe leaf\n",
    "df_leaf = pd.DataFrame( rf.apply( X ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP( n_neighbors=20, random_state=42,  )\n",
    "embedding = reducer.fit_transform( df_leaf )\n",
    "\n",
    "# embedding\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]\n",
    "# df_tree['embedding_z'] = embedding[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Hyperparameter Fine-Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df_tree.copy()\n",
    "X = df7.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Machine Learnign Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "\n",
    "# model trainig \n",
    "kmeans.fit ( X )\n",
    "\n",
    "# clustering\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSS value: 35485.94140625\n",
      "SS Value: 0.5762630105018616\n"
     ]
    }
   ],
   "source": [
    "# WSS \n",
    "print( f'WSS value: {kmeans.inertia_}')\n",
    "\n",
    "# Silhouette\n",
    "print(f'SS Value: {metrics.silhouette_score( X, labels, metric=\"euclidean\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.0 Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = X.copy()\n",
    "df9['cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['cluster'] = labels\n",
    "df9 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9['recency_days'] = df9['recency_days'].apply( lambda x: 1/ x if x != 0 else 0)\n",
    "df9['qtde_returns'] = df9['qtde_returns'].apply( lambda x: 1/ x if x != 0 else 0)\n",
    "df9['avg_recency_days'] = df9['avg_recency_days'].apply( lambda x: 1/ x if x != 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers\n",
    "df_cluster = df9[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['per_customer'] = 100 * df_cluster['customer_id'] / df_cluster['customer_id'].sum()\n",
    "\n",
    "# Avg revenue\n",
    "df_avg_revenue = df9[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_revenue, on='cluster', how='inner')\n",
    "\n",
    "# Avg recency\n",
    "df_avg_recency = df9[['recency_days', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_recency, on='cluster', how='inner')\n",
    "\n",
    "# purchases\n",
    "df_avg_frequency = df9[['qtde_invoices', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_frequency, on='cluster', how='inner')\n",
    "\n",
    "# # Avg Ticket\n",
    "# df_avg_ticket = df9[['revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "# df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# returns\n",
    "df_avg_ticket = df9[['qtde_returns', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# product_quantity\n",
    "df_avg_ticket = df9[['qtde_products', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# avg_frquency\n",
    "df_avg_ticket = df9[['frequency', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# quantity\n",
    "df_avg_ticket = df9[['avg_basket_size', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_ticket, on='cluster', how='inner')\n",
    "\n",
    "# AVG revenue returned\n",
    "df_avg_money_returned = df9.groupby('cluster')['revenue_returned'].mean().reset_index()\n",
    "df_cluster = pd.merge(df_cluster, df_avg_money_returned, on='cluster', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>per_customer</th>\n",
       "      <th>gross_revenue</th>\n",
       "      <th>recency_days</th>\n",
       "      <th>qtde_invoices</th>\n",
       "      <th>qtde_returns</th>\n",
       "      <th>qtde_products</th>\n",
       "      <th>frequency</th>\n",
       "      <th>avg_basket_size</th>\n",
       "      <th>revenue_returned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>433</td>\n",
       "      <td>7.603161</td>\n",
       "      <td>12091.152102</td>\n",
       "      <td>30.050808</td>\n",
       "      <td>15.600462</td>\n",
       "      <td>336.785219</td>\n",
       "      <td>370.685912</td>\n",
       "      <td>0.138669</td>\n",
       "      <td>886.855937</td>\n",
       "      <td>-521.349607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>3.792801</td>\n",
       "      <td>3686.197454</td>\n",
       "      <td>119.486111</td>\n",
       "      <td>3.305556</td>\n",
       "      <td>10.180556</td>\n",
       "      <td>313.361111</td>\n",
       "      <td>0.713998</td>\n",
       "      <td>900.065978</td>\n",
       "      <td>-25.495880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>6.637401</td>\n",
       "      <td>2559.131958</td>\n",
       "      <td>40.230159</td>\n",
       "      <td>6.642857</td>\n",
       "      <td>21.944444</td>\n",
       "      <td>158.732804</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>329.378138</td>\n",
       "      <td>-45.562778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>809</td>\n",
       "      <td>14.205443</td>\n",
       "      <td>1602.229370</td>\n",
       "      <td>64.672435</td>\n",
       "      <td>4.074166</td>\n",
       "      <td>13.105068</td>\n",
       "      <td>109.128554</td>\n",
       "      <td>0.241996</td>\n",
       "      <td>319.153840</td>\n",
       "      <td>-29.735859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>374</td>\n",
       "      <td>6.567164</td>\n",
       "      <td>1176.347727</td>\n",
       "      <td>117.334225</td>\n",
       "      <td>2.467914</td>\n",
       "      <td>5.026738</td>\n",
       "      <td>114.799465</td>\n",
       "      <td>0.561089</td>\n",
       "      <td>289.690618</td>\n",
       "      <td>-13.897299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>564</td>\n",
       "      <td>9.903424</td>\n",
       "      <td>932.056915</td>\n",
       "      <td>99.930851</td>\n",
       "      <td>2.434397</td>\n",
       "      <td>7.420213</td>\n",
       "      <td>66.781915</td>\n",
       "      <td>0.386474</td>\n",
       "      <td>244.434752</td>\n",
       "      <td>-15.991064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "      <td>6.602283</td>\n",
       "      <td>548.072021</td>\n",
       "      <td>97.321809</td>\n",
       "      <td>2.210106</td>\n",
       "      <td>3.678191</td>\n",
       "      <td>42.821809</td>\n",
       "      <td>0.426589</td>\n",
       "      <td>186.620966</td>\n",
       "      <td>-10.138697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>794</td>\n",
       "      <td>13.942054</td>\n",
       "      <td>442.860227</td>\n",
       "      <td>136.267003</td>\n",
       "      <td>1.714106</td>\n",
       "      <td>2.068010</td>\n",
       "      <td>41.696474</td>\n",
       "      <td>0.650830</td>\n",
       "      <td>128.424160</td>\n",
       "      <td>-7.282380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>822</td>\n",
       "      <td>14.433714</td>\n",
       "      <td>259.274185</td>\n",
       "      <td>162.371046</td>\n",
       "      <td>1.238443</td>\n",
       "      <td>1.709246</td>\n",
       "      <td>16.588808</td>\n",
       "      <td>0.828490</td>\n",
       "      <td>108.228994</td>\n",
       "      <td>-5.005401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>443</td>\n",
       "      <td>7.778753</td>\n",
       "      <td>143.865305</td>\n",
       "      <td>185.076749</td>\n",
       "      <td>1.130926</td>\n",
       "      <td>0.801354</td>\n",
       "      <td>13.550790</td>\n",
       "      <td>0.953968</td>\n",
       "      <td>36.414167</td>\n",
       "      <td>-2.852867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>486</td>\n",
       "      <td>8.533802</td>\n",
       "      <td>18.970041</td>\n",
       "      <td>197.425926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615226</td>\n",
       "      <td>3.055556</td>\n",
       "      <td>1.002058</td>\n",
       "      <td>5.100823</td>\n",
       "      <td>-1.776975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster  customer_id  per_customer  gross_revenue  recency_days  \\\n",
       "6         6          433      7.603161   12091.152102     30.050808   \n",
       "9         9          216      3.792801    3686.197454    119.486111   \n",
       "0         0          378      6.637401    2559.131958     40.230159   \n",
       "3         3          809     14.205443    1602.229370     64.672435   \n",
       "4         4          374      6.567164    1176.347727    117.334225   \n",
       "7         7          564      9.903424     932.056915     99.930851   \n",
       "1         1          376      6.602283     548.072021     97.321809   \n",
       "8         8          794     13.942054     442.860227    136.267003   \n",
       "10       10          822     14.433714     259.274185    162.371046   \n",
       "2         2          443      7.778753     143.865305    185.076749   \n",
       "5         5          486      8.533802      18.970041    197.425926   \n",
       "\n",
       "    qtde_invoices  qtde_returns  qtde_products  frequency  avg_basket_size  \\\n",
       "6       15.600462    336.785219     370.685912   0.138669       886.855937   \n",
       "9        3.305556     10.180556     313.361111   0.713998       900.065978   \n",
       "0        6.642857     21.944444     158.732804   0.099242       329.378138   \n",
       "3        4.074166     13.105068     109.128554   0.241996       319.153840   \n",
       "4        2.467914      5.026738     114.799465   0.561089       289.690618   \n",
       "7        2.434397      7.420213      66.781915   0.386474       244.434752   \n",
       "1        2.210106      3.678191      42.821809   0.426589       186.620966   \n",
       "8        1.714106      2.068010      41.696474   0.650830       128.424160   \n",
       "10       1.238443      1.709246      16.588808   0.828490       108.228994   \n",
       "2        1.130926      0.801354      13.550790   0.953968        36.414167   \n",
       "5        1.000000      0.615226       3.055556   1.002058         5.100823   \n",
       "\n",
       "    revenue_returned  \n",
       "6        -521.349607  \n",
       "9         -25.495880  \n",
       "0         -45.562778  \n",
       "3         -29.735859  \n",
       "4         -13.897299  \n",
       "7         -15.991064  \n",
       "1         -10.138697  \n",
       "8          -7.282380  \n",
       "10         -5.005401  \n",
       "2          -2.852867  \n",
       "5          -1.776975  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.sort_values('gross_revenue', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.0 Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5695, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import create_engine, text\n",
    "\n",
    "# # Database connection details\n",
    "# host = 'cluter-db.cx0iy0e6kyf8.sa-east-1.rds.amazonaws.com'\n",
    "# port = '5432'\n",
    "# database = 'postgres'\n",
    "# user = 'natan'\n",
    "# pwd = 'natan2019'\n",
    "\n",
    "# # Connection string\n",
    "# endpoint = f'postgresql://{user}:{pwd}@{host}:{port}/{database}'\n",
    "# conn = create_engine( endpoint )\n",
    "\n",
    "# # # SQL query to create the table\n",
    "# # query_create_table_insiders = \"\"\"\n",
    "# #     CREATE TABLE insiders (\n",
    "# #         customer_id             INTEGER,\n",
    "# #         gross_revenue           REAL,\n",
    "# #         recency_days            REAL,\n",
    "# #         qtde_invoices           INTEGER,\n",
    "# #         qtde_items              INTEGER,\n",
    "# #         qtde_products           INTEGER,\n",
    "# #         avg_ticket              REAL,\n",
    "# #         avg_recency_days        REAL,\n",
    "# #         frequency               REAL,\n",
    "# #         qtde_returns            REAL,\n",
    "# #         avg_basket_size         REAL,\n",
    "# #         avg_unique_basket_size  REAL,\n",
    "# #         revenue_returned        REAL,\n",
    "# #         cluster                 INTEGER\n",
    "# #     )\n",
    "# # \"\"\"\n",
    "\n",
    "# # # Execute the query as raw SQL\n",
    "# # with engine.connect() as conn:\n",
    "# #     conn.execute(text(query_create_table_insiders))\n",
    "\n",
    "# # Assuming df9 is your DataFrame\n",
    "# df9.to_sql('insiders', con=conn, if_exists='append', index=False)\n",
    "# conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
